{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb27177",
   "metadata": {},
   "source": [
    "# Evaluate Generated Code\n",
    "This notebook loads the code generated by an LLM and uses the modified human-eval package to evaluate how well the code was generated by computing the Pass@1 score. Pass@5 and Pass@10 scores can also be computed.\n",
    "* [Original package](https://github.com/openai/human-eval) - evaluates code generaion models only on the [HumanEval](https://huggingface.co/datasets/openai/openai_humaneval) dataset.\n",
    "* [My modifications](https://github.com/agnedil/code-generation/tree/main/modified-openai-human-eval-code) - I made an extensive addition to enable the evaluation on three more datasets: [MBPP](https://huggingface.co/datasets/google-research-datasets/mbpp), [LBPP](https://huggingface.co/datasets/CohereForAI/lbpp), and [Big Code Benchmark](https://huggingface.co/datasets/bigcode/bigcodebench)\n",
    "\n",
    "__This version walks over the entire directory with all models and evaluated them in bulk, populating the dataframe with pass@1 scores for all models / prompt types / cleaning modes__.\n",
    "\n",
    "The models should be evaluated in a specific order. This is required to populate the dataframe with results in the correct order. The order of prompts should be as follows:\n",
    "* prompt_basic\n",
    "* prompt\n",
    "* prompt_full\n",
    "\n",
    "Within each prompt, the order of cleaning modes should be as follows:\n",
    "* raw\n",
    "* cleaned_partially\n",
    "* cleaned_fully\n",
    "* cleaned_fully_light\n",
    "\n",
    "The code in Section 2 enforces this order for prompts. The code in Section 3 enforces it for cleaning modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b59ff23-dd63-454b-a500-6547ddddd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from human_eval.evaluation import evaluate_functional_correctness\n",
    "from human_eval.data import stream_jsonl, write_jsonl\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "from helpers import get_code_in_fences, clean_code, clean_code_light, read_problems\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94e15d",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a8d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:       lbpp \n",
      "Cleaning mode: lbpp\n"
     ]
    }
   ],
   "source": [
    "# select dataset\n",
    "idx = 2\n",
    "dataset_names = ['human_eval', 'big_code', 'lbpp', 'mbpp']\n",
    "dataset_name  = dataset_names[idx]\n",
    "mode          = dataset_names[idx]\n",
    "print('Dataset:      ', dataset_name, '\\nCleaning mode:', mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a33734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset for 'human_eval' and 'big_code' (func signature needed)\n",
    "# no need to load for 'lbpp' and 'mbpp'\n",
    "if dataset_name == 'human_eval':\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(\"openai/openai_humaneval\")\n",
    "    tasks   = {i['task_id']:i for i in dataset['test']}\n",
    "elif dataset_name == 'big_code':\n",
    "    file = 'data/Big_Code_Bench_Test.jsonl.gz'\n",
    "    tasks = read_problems(file)\n",
    "    \n",
    "if dataset_name in ['human_eval', 'big_code',]:    \n",
    "    print(f'Type of tasks: {type(tasks)}\\n')\n",
    "    counter = 0\n",
    "    for k,v in tasks.items():\n",
    "        if counter == 2:\n",
    "            break\n",
    "        print(f'task_id: {k}', type(k))\n",
    "        for k2, v2 in v.items():\n",
    "            print(f'\\n{k2}:\\n{v2}')\n",
    "        print('\\n' + '='*100 + '\\n')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3cdf76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if dataset_name == 'human_eval':\n",
    "    for task_id in ['HumanEval/1', 'HumanEval/10']:\n",
    "        print(task_id, '\\n', tasks[task_id]['prompt'], sep='')\n",
    "elif dataset_name == 'big_code':\n",
    "    for task_id in ['BigCodeBench/1', 'BigCodeBench/10']:\n",
    "        print(task_id, '\\n', tasks[task_id]['prompt'], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94f27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b07489",
   "metadata": {},
   "source": [
    "## 2. Get filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4cf1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective:  task\n",
      "Num models: 9\n"
     ]
    }
   ],
   "source": [
    "# select prompt type used in filenames: complete_code OR complete_task\n",
    "idx = 1\n",
    "objectives = ['code', 'task']\n",
    "objective  = objectives[idx]\n",
    "print('Objective: ', objective)\n",
    "prompt_basic_key  = f'complete_{objective}_prompt_basic'\n",
    "prompt_medium_key = f'complete_{objective}_prompt'\n",
    "prompt_full_key   = f'complete_{objective}_prompt_full'\n",
    "\n",
    "# models to be evaluated\n",
    "model_names = [\n",
    "    'phixtral-2x2',\n",
    "    'Solar-10.7B',\n",
    "    'Llama-3.1-8B',\n",
    "    'codegemma-7b-it',\n",
    "    'deepseek-coder-6.7b',\n",
    "    'OpenCodeInterpreter-DS-6.7B',\n",
    "    'Artigenz-Coder-DS-6.7B',\n",
    "    'CodeQwen1.5-7B-Chat',\n",
    "    'Nxcode-CQ-7B-orpo',\n",
    "    #'phixtral-4x2',\n",
    "    #'mistral_7b',\n",
    "    #'mistral_3b',\n",
    "    #'mistral_8B',\n",
    "    #'nemo',\n",
    "    #'codestral',\n",
    "]\n",
    "print('Num models:', len(model_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86aaa130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models with JSONL files found:\n",
      "9\n",
      "phixtral-2x2\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186.jsonl \n",
      "\n",
      "Nxcode-CQ-7B-orpo\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246.jsonl \n",
      "\n",
      "Artigenz-Coder-DS-6.7B\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872.jsonl \n",
      "\n",
      "codegemma-7b-it\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624.jsonl \n",
      "\n",
      "Llama-3.1-8B\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287.jsonl \n",
      "\n",
      "CodeQwen1.5-7B-Chat\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182.jsonl \n",
      "\n",
      "Solar-10.7B\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894.jsonl \n",
      "\n",
      "deepseek-coder-6.7b\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884.jsonl \n",
      "\n",
      "OpenCodeInterpreter-DS-6.7B\n",
      "Num files: 3\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730.jsonl\n",
      "logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427.jsonl \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group files by model\n",
    "wdir = 'logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087'\n",
    "jsonl_files = defaultdict(list)\n",
    "\n",
    "for root, dirs, files in os.walk(wdir):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.jsonl'):\n",
    "            model_name = [name for name in model_names if name in filename]\n",
    "            assert len(model_name)==1, f'None or too many model names in file {filename}'\n",
    "            filepath = os.path.join(root, filename)            \n",
    "            jsonl_files[model_name[0]].append(filepath)\n",
    "\n",
    "print(\"Models with JSONL files found:\")\n",
    "print(len(jsonl_files))\n",
    "for model, files in jsonl_files.items():\n",
    "    print(model)\n",
    "    print('Num files:', len(files))\n",
    "    print('\\n'.join(files), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aadde578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phixtral-2x2\n",
      "3\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411.jsonl \n",
      "\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186.jsonl \n",
      "\n",
      "Nxcode-CQ-7B-orpo\n",
      "3\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547.jsonl \n",
      "\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246.jsonl \n",
      "\n",
      "Artigenz-Coder-DS-6.7B\n",
      "3\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546.jsonl \n",
      "\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872.jsonl \n",
      "\n",
      "codegemma-7b-it\n",
      "3\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624.jsonl \n",
      "\n",
      "Llama-3.1-8B\n",
      "3\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799.jsonl \n",
      "\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287.jsonl \n",
      "\n",
      "CodeQwen1.5-7B-Chat\n",
      "3\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798.jsonl \n",
      "\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182.jsonl \n",
      "\n",
      "Solar-10.7B\n",
      "3\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062.jsonl \n",
      "\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894.jsonl \n",
      "\n",
      "deepseek-coder-6.7b\n",
      "3\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884.jsonl \n",
      "\n",
      "OpenCodeInterpreter-DS-6.7B\n",
      "3\n",
      "\tcomplete_task_prompt_full: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242.jsonl \n",
      "\n",
      "\tcomplete_task_prompt: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730.jsonl \n",
      "\n",
      "\tcomplete_task_prompt_basic: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427.jsonl \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert to dict of dict with prompt types as keys\n",
    "prompt_dict = dict()\n",
    "for model_name, files in jsonl_files.items():\n",
    "    result = dict()\n",
    "    for file in files:\n",
    "        if prompt_basic_key in file:\n",
    "            result[prompt_basic_key] = file\n",
    "        elif prompt_full_key in file:\n",
    "            result[prompt_full_key] = file\n",
    "        else:\n",
    "            result[prompt_medium_key] = file       # the remaining file - neither full nor basic prompt\n",
    "    #assert len(result)==3, f'One or more files are missing in {result}'\n",
    "    prompt_dict[ model_name ] = result\n",
    "\n",
    "for model_name, prompt_file_pair in prompt_dict.items():\n",
    "    print(model_name)\n",
    "    print(len(prompt_file_pair))\n",
    "    for prompt, file in prompt_file_pair.items():\n",
    "        print(f'\\t{prompt}: {file}', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23ffd9",
   "metadata": {},
   "source": [
    "## 2. Clean and Evaluate Generated Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd28f1",
   "metadata": {},
   "source": [
    "```\n",
    ":param mode:\n",
    "       'human_eval' - using the HumanEval dataset with or without func header;\n",
    "       'mbpp' - using the MBPP dataset;\n",
    "       'lbpp' - using the LBPP dataset;\n",
    "       'big_code' - using the Big Code Benchmark dataset.\n",
    ":param k:\n",
    "        [1] - pass@1 score\n",
    "        [1,5] - pass@1 and pass@5 scores, etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccef8194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: phixtral-2x2\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 16140.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 42242.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6246.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 50201.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4344.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51393.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4438.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 48258.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110343_5411.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.024691358024691357\n",
      "0.12962962962962962\n",
      "0.12345679012345678\n",
      "0.12962962962962962\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7505.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 45274.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5281.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51608.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4309.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51231.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5334.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 48841.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110455_4025.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.012345679012345678\n",
      "0.12345679012345678\n",
      "0.12962962962962962\n",
      "0.13580246913580246\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4928.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 47314.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5208.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 57325.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6910.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 47803.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5967.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 46510.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/phixtral-2x2_8/phixtral-2x2_8_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110509_7186.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.012345679012345678\n",
      "0.08641975308641975\n",
      "0.11728395061728394\n",
      "0.12345679012345678\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: Nxcode-CQ-7B-orpo\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6880.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 42809.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4915.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 55617.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 3496.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 58104.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6033.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 53063.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030642_7246.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.006172839506172839\n",
      "0.19753086419753085\n",
      "0.20987654320987653\n",
      "0.20987654320987653\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4886.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 49198.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 10323.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 55440.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 38134.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 54580.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 43690.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 49862.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030705_0898.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.012345679012345678\n",
      "0.21604938271604937\n",
      "0.20987654320987653\n",
      "0.21604938271604937\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4798.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56783.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7029.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56510.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6975.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 58464.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4992.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 52187.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nxcode-CQ-7B/Nxcode-CQ-7B-orpo_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030726_5547.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.018518518518518517\n",
      "0.15432098765432098\n",
      "0.19753086419753085\n",
      "0.19753086419753085\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: Artigenz-Coder-DS-6.7B\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 1345.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 39735.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 10291.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 47931.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4246.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 48855.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4266.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 45988.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030434_5546.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.024691358024691357\n",
      "0.2777777777777778\n",
      "0.2345679012345679\n",
      "0.2777777777777778\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11076.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 39754.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6141.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 48097.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5716.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 48299.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5207.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 49586.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030500_9121.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.24074074074074073\n",
      "0.22839506172839505\n",
      "0.24691358024691357\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7593.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 44358.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4317.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 58144.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7859.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 59666.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 8168.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 53150.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Artigenz-Coder-DS-6.7B/Artigenz-Coder-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030507_7872.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.24074074074074073\n",
      "0.2222222222222222\n",
      "0.24074074074074073\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "('Artigenz-Coder-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2345679012345679, 0.2777777777777778, 0.0, 0.24074074074074073, 0.22839506172839505, 0.24691358024691357, 0.0, 0.24074074074074073, 0.2222222222222222, 0.24074074074074073])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: codegemma-7b-it\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 39793.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 46741.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7268.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 45453.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11381.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 46847.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5919.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 43511.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005046_4507.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.11728395061728394\n",
      "0.1419753086419753\n",
      "0.14814814814814814\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6511.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51219.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5978.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51592.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5205.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51038.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11676.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51188.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_004929_5516.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.1111111111111111\n",
      "0.17901234567901234\n",
      "0.17901234567901234\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 12162.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 59167.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7448.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 52534.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 12514.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 55571.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5555.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 54502.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/codegemma-7b-it/codegemma-7b-it_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_004945_3624.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.13580246913580246\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "('Artigenz-Coder-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2345679012345679, 0.2777777777777778, 0.0, 0.24074074074074073, 0.22839506172839505, 0.24691358024691357, 0.0, 0.24074074074074073, 0.2222222222222222, 0.24074074074074073])\n",
      "('codegemma-7b-it', [0.0, 0.11728395061728394, 0.1419753086419753, 0.14814814814814814, 0.0, 0.1111111111111111, 0.17901234567901234, 0.17901234567901234, 0.0, 0.13580246913580246, 0.16666666666666666, 0.16666666666666666])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: Llama-3.1-8B\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6925.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 32824.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4515.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 43865.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 10582.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 36876.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5983.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 42823.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250620_110633_1799.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.2222222222222222\n",
      "0.17901234567901234\n",
      "0.2222222222222222\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7290.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 36331.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5376.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 35983.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6945.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:14<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 39444.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11555.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 37368.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250620_110703_7061.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.16049382716049382\n",
      "0.19135802469135801\n",
      "0.21604938271604937\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 52578.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 64289.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7095.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 59105.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7755.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 54580.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4309.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 50492.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Llama-3.1-8B/Meta-Llama-3.1-8B-Instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250620_110711_1287.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.2037037037037037\n",
      "0.2345679012345679\n",
      "0.2345679012345679\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "('Artigenz-Coder-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2345679012345679, 0.2777777777777778, 0.0, 0.24074074074074073, 0.22839506172839505, 0.24691358024691357, 0.0, 0.24074074074074073, 0.2222222222222222, 0.24074074074074073])\n",
      "('codegemma-7b-it', [0.0, 0.11728395061728394, 0.1419753086419753, 0.14814814814814814, 0.0, 0.1111111111111111, 0.17901234567901234, 0.17901234567901234, 0.0, 0.13580246913580246, 0.16666666666666666, 0.16666666666666666])\n",
      "('Llama-3.1-8B', [0.0, 0.2222222222222222, 0.17901234567901234, 0.2222222222222222, 0.0, 0.16049382716049382, 0.19135802469135801, 0.21604938271604937, 0.0, 0.2037037037037037, 0.2345679012345679, 0.2345679012345679])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: CodeQwen1.5-7B-Chat\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5102.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 45377.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 47999.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 55422.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4774.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 55156.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 10270.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 62423.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_030558_0798.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.024691358024691357\n",
      "0.19753086419753085\n",
      "0.2037037037037037\n",
      "0.2037037037037037\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5398.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 50108.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 12870.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:14<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 57060.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11858.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 52255.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7429.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:14<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 54673.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_030618_0182.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.20987654320987653\n",
      "0.2222222222222222\n",
      "0.2222222222222222\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 49705.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 58951.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11448.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 57773.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7425.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56477.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11079.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 52721.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/CodeQwen1.5-7B-Chat/CodeQwen1.5-7B-Chat_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_030618_5304.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.16049382716049382\n",
      "0.18518518518518517\n",
      "0.18518518518518517\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "('Artigenz-Coder-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2345679012345679, 0.2777777777777778, 0.0, 0.24074074074074073, 0.22839506172839505, 0.24691358024691357, 0.0, 0.24074074074074073, 0.2222222222222222, 0.24074074074074073])\n",
      "('codegemma-7b-it', [0.0, 0.11728395061728394, 0.1419753086419753, 0.14814814814814814, 0.0, 0.1111111111111111, 0.17901234567901234, 0.17901234567901234, 0.0, 0.13580246913580246, 0.16666666666666666, 0.16666666666666666])\n",
      "('Llama-3.1-8B', [0.0, 0.2222222222222222, 0.17901234567901234, 0.2222222222222222, 0.0, 0.16049382716049382, 0.19135802469135801, 0.21604938271604937, 0.0, 0.2037037037037037, 0.2345679012345679, 0.2345679012345679])\n",
      "('CodeQwen1.5-7B-Chat', [0.024691358024691357, 0.19753086419753085, 0.2037037037037037, 0.2037037037037037, 0.0, 0.20987654320987653, 0.2222222222222222, 0.2222222222222222, 0.0, 0.16049382716049382, 0.18518518518518517, 0.18518518518518517])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: Solar-10.7B\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6572.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 43372.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 10920.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51987.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4305.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 46860.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4145.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:15<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 44427.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250624_022840_4744.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.024691358024691357\n",
      "0.05555555555555555\n",
      "0.09259259259259259\n",
      "0.09259259259259259\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5351.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 45985.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4707.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 52869.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4658.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56627.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5435.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:13<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 51428.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250624_022858_4894.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.04938271604938271\n",
      "0.07407407407407407\n",
      "0.07407407407407407\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5902.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 61647.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4576.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 57980.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7232.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 59865.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7744.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 61736.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/Nous-Hermes-2-Solar-10.7B/Nous-Hermes-2-Solar-10.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250624_022934_3062.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.037037037037037035\n",
      "0.08641975308641975\n",
      "0.08641975308641975\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "('Artigenz-Coder-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2345679012345679, 0.2777777777777778, 0.0, 0.24074074074074073, 0.22839506172839505, 0.24691358024691357, 0.0, 0.24074074074074073, 0.2222222222222222, 0.24074074074074073])\n",
      "('codegemma-7b-it', [0.0, 0.11728395061728394, 0.1419753086419753, 0.14814814814814814, 0.0, 0.1111111111111111, 0.17901234567901234, 0.17901234567901234, 0.0, 0.13580246913580246, 0.16666666666666666, 0.16666666666666666])\n",
      "('Llama-3.1-8B', [0.0, 0.2222222222222222, 0.17901234567901234, 0.2222222222222222, 0.0, 0.16049382716049382, 0.19135802469135801, 0.21604938271604937, 0.0, 0.2037037037037037, 0.2345679012345679, 0.2345679012345679])\n",
      "('CodeQwen1.5-7B-Chat', [0.024691358024691357, 0.19753086419753085, 0.2037037037037037, 0.2037037037037037, 0.0, 0.20987654320987653, 0.2222222222222222, 0.2222222222222222, 0.0, 0.16049382716049382, 0.18518518518518517, 0.18518518518518517])\n",
      "('Solar-10.7B', [0.024691358024691357, 0.05555555555555555, 0.09259259259259259, 0.09259259259259259, 0.0, 0.04938271604938271, 0.07407407407407407, 0.07407407407407407, 0.0, 0.037037037037037035, 0.08641975308641975, 0.08641975308641975])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: deepseek-coder-6.7b\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11170.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 41098.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5345.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 55143.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4325.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 58757.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 10548.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 52578.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005353_7884.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.006172839506172839\n",
      "0.2716049382716049\n",
      "0.2716049382716049\n",
      "0.2716049382716049\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 7041.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 45851.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 8050.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 52175.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6973.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 54933.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 10890.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 58931.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005425_3382.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.2716049382716049\n",
      "0.25925925925925924\n",
      "0.2716049382716049\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4233.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 55767.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 8340.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 58040.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6173.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 62641.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4502.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:12<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 57383.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/deepseek-coder-6.7b/deepseek-coder-6.7b-instruct_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005453_2758.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.21604938271604937\n",
      "0.22839506172839505\n",
      "0.22839506172839505\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "('Artigenz-Coder-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2345679012345679, 0.2777777777777778, 0.0, 0.24074074074074073, 0.22839506172839505, 0.24691358024691357, 0.0, 0.24074074074074073, 0.2222222222222222, 0.24074074074074073])\n",
      "('codegemma-7b-it', [0.0, 0.11728395061728394, 0.1419753086419753, 0.14814814814814814, 0.0, 0.1111111111111111, 0.17901234567901234, 0.17901234567901234, 0.0, 0.13580246913580246, 0.16666666666666666, 0.16666666666666666])\n",
      "('Llama-3.1-8B', [0.0, 0.2222222222222222, 0.17901234567901234, 0.2222222222222222, 0.0, 0.16049382716049382, 0.19135802469135801, 0.21604938271604937, 0.0, 0.2037037037037037, 0.2345679012345679, 0.2345679012345679])\n",
      "('CodeQwen1.5-7B-Chat', [0.024691358024691357, 0.19753086419753085, 0.2037037037037037, 0.2037037037037037, 0.0, 0.20987654320987653, 0.2222222222222222, 0.2222222222222222, 0.0, 0.16049382716049382, 0.18518518518518517, 0.18518518518518517])\n",
      "('Solar-10.7B', [0.024691358024691357, 0.05555555555555555, 0.09259259259259259, 0.09259259259259259, 0.0, 0.04938271604938271, 0.07407407407407407, 0.07407407407407407, 0.0, 0.037037037037037035, 0.08641975308641975, 0.08641975308641975])\n",
      "('deepseek-coder-6.7b', [0.006172839506172839, 0.2716049382716049, 0.2716049382716049, 0.2716049382716049, 0.0, 0.2716049382716049, 0.25925925925925924, 0.2716049382716049, 0.0, 0.21604938271604937, 0.22839506172839505, 0.22839506172839505])\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "Model: OpenCodeInterpreter-DS-6.7B\n",
      "\n",
      "Prompt key: complete_task_prompt_basic\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 43913.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 39959.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5699.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [16:17<00:00,  6.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 60242.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5542.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56727.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11222.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56016.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_basic_temperature1.0_topP0.87_completions_20250621_005525_4427.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.024691358024691357\n",
      "0.2777777777777778\n",
      "0.2654320987654321\n",
      "0.2777777777777778\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 5443.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 45175.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 11985.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [16:46<00:00,  6.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56651.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 13316.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:14<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 59582.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 53067.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:14<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 57582.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_temperature1.0_topP0.87_completions_20250621_005551_7730.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.2654320987654321\n",
      "0.2654320987654321\n",
      "0.2654320987654321\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "Prompt key: complete_task_prompt_full\n",
      "\n",
      "File: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242.jsonl\n",
      "Number of completions: 162\n",
      "\n",
      "EVALUATING RAW FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 4707.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:10<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 47619.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING PARTIALLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 13704.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [15:10<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242_cleaned_partially.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 56684.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 49031.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242_cleaned_fully.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 63207.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING FULLY CLEANED LIGHT FILE\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162it [00:00, 6423.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:11<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242_cleaned_fully_light.jsonl_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 62480.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for: logs_results/final-round-one-model-top-p_experiment/LBPP/top-p_087/OpenCodeInterpreter-DS-6.7B/OpenCodeInterpreter-DS-6.7B_complete_task_prompt_full_temperature1.0_topP0.87_completions_20250621_005626_7242.jsonl\n",
      "\n",
      "Raw score\n",
      "Partially cleaned score\n",
      "Fully cleaned score\n",
      "Fully light cleaned score\n",
      "\n",
      "0.0\n",
      "0.2716049382716049\n",
      "0.29012345679012347\n",
      "0.2839506172839506\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Interim  results:\n",
      "('phixtral-2x2', [0.024691358024691357, 0.12962962962962962, 0.12345679012345678, 0.12962962962962962, 0.012345679012345678, 0.12345679012345678, 0.12962962962962962, 0.13580246913580246, 0.012345679012345678, 0.08641975308641975, 0.11728395061728394, 0.12345679012345678])\n",
      "('Nxcode-CQ-7B-orpo', [0.006172839506172839, 0.19753086419753085, 0.20987654320987653, 0.20987654320987653, 0.012345679012345678, 0.21604938271604937, 0.20987654320987653, 0.21604938271604937, 0.018518518518518517, 0.15432098765432098, 0.19753086419753085, 0.19753086419753085])\n",
      "('Artigenz-Coder-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2345679012345679, 0.2777777777777778, 0.0, 0.24074074074074073, 0.22839506172839505, 0.24691358024691357, 0.0, 0.24074074074074073, 0.2222222222222222, 0.24074074074074073])\n",
      "('codegemma-7b-it', [0.0, 0.11728395061728394, 0.1419753086419753, 0.14814814814814814, 0.0, 0.1111111111111111, 0.17901234567901234, 0.17901234567901234, 0.0, 0.13580246913580246, 0.16666666666666666, 0.16666666666666666])\n",
      "('Llama-3.1-8B', [0.0, 0.2222222222222222, 0.17901234567901234, 0.2222222222222222, 0.0, 0.16049382716049382, 0.19135802469135801, 0.21604938271604937, 0.0, 0.2037037037037037, 0.2345679012345679, 0.2345679012345679])\n",
      "('CodeQwen1.5-7B-Chat', [0.024691358024691357, 0.19753086419753085, 0.2037037037037037, 0.2037037037037037, 0.0, 0.20987654320987653, 0.2222222222222222, 0.2222222222222222, 0.0, 0.16049382716049382, 0.18518518518518517, 0.18518518518518517])\n",
      "('Solar-10.7B', [0.024691358024691357, 0.05555555555555555, 0.09259259259259259, 0.09259259259259259, 0.0, 0.04938271604938271, 0.07407407407407407, 0.07407407407407407, 0.0, 0.037037037037037035, 0.08641975308641975, 0.08641975308641975])\n",
      "('deepseek-coder-6.7b', [0.006172839506172839, 0.2716049382716049, 0.2716049382716049, 0.2716049382716049, 0.0, 0.2716049382716049, 0.25925925925925924, 0.2716049382716049, 0.0, 0.21604938271604937, 0.22839506172839505, 0.22839506172839505])\n",
      "('OpenCodeInterpreter-DS-6.7B', [0.024691358024691357, 0.2777777777777778, 0.2654320987654321, 0.2777777777777778, 0.0, 0.2654320987654321, 0.2654320987654321, 0.2654320987654321, 0.0, 0.2716049382716049, 0.29012345679012347, 0.2839506172839506])\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_res = defaultdict(list)\n",
    "for model_name, prompt_file_pair in prompt_dict.items():\n",
    "    print('\\nModel:', model_name)\n",
    "    \n",
    "    # enforce the order of prompts    \n",
    "    prompt_keys = [prompt_basic_key, prompt_medium_key, prompt_full_key]\n",
    "\n",
    "    for prompt_key in prompt_keys:\n",
    "        print('\\nPrompt key:', prompt_key)\n",
    "\n",
    "        # load file with results for cleaning\n",
    "        file_name = prompt_file_pair[ prompt_key ]\n",
    "        results   = list(stream_jsonl(file_name))\n",
    "        print(f'\\nFile: {file_name}\\nNumber of completions: {len(results)}')\n",
    "\n",
    "        # apply different degrees of cleaning\n",
    "        results_cleaned_partially, results_cleaned_fully, results_cleaned_fully_light = [], [], []\n",
    "        for item in results:\n",
    "            task_id    = item['task_id']\n",
    "            completion = item['completion']\n",
    "            \n",
    "            # no signature if lbpp and mbpp\n",
    "            if dataset_name in ['lbpp', 'mbpp']:\n",
    "                signature = None\n",
    "            else:\n",
    "                signature  = tasks[task_id]['prompt']\n",
    "            completion_cleaned_partially   = get_code_in_fences(completion)\n",
    "            completion_cleaned_fully       = clean_code(completion, signature)\n",
    "            completion_cleaned_fully_light = clean_code_light(completion, signature)\n",
    "\n",
    "            results_cleaned_partially.append(  {'task_id': task_id, 'completion': completion_cleaned_partially} )\n",
    "            results_cleaned_fully.append(      {'task_id': task_id, 'completion': completion_cleaned_fully} )\n",
    "            results_cleaned_fully_light.append( {'task_id': task_id, 'completion': completion_cleaned_fully_light} )\n",
    "            \n",
    "        # save cleaned files\n",
    "        file_name_cleaned_partially   = file_name.replace('.jsonl', '') + '_cleaned_partially.jsonl'\n",
    "        file_name_cleaned_fully       = file_name.replace('.jsonl', '') + '_cleaned_fully.jsonl'\n",
    "        file_name_cleaned_fully_light = file_name.replace('.jsonl', '') + '_cleaned_fully_light.jsonl'\n",
    "\n",
    "        write_jsonl(file_name_cleaned_partially, results_cleaned_partially)\n",
    "        write_jsonl(file_name_cleaned_fully, results_cleaned_fully)\n",
    "        write_jsonl(file_name_cleaned_fully_light, results_cleaned_fully_light)\n",
    "        \n",
    "        print('\\nEVALUATING RAW FILE')\n",
    "        pass1_score_raw                   = evaluate_functional_correctness(\n",
    "            file_name,\n",
    "            k=[1],\n",
    "            mode=mode, )\n",
    "        \n",
    "        print('\\nEVALUATING PARTIALLY CLEANED FILE')\n",
    "        pass1_score_cleaned_partially     = evaluate_functional_correctness(\n",
    "            file_name_cleaned_partially,\n",
    "            k=[1],\n",
    "            mode=mode, )\n",
    "        \n",
    "        print('\\nEVALUATING FULLY CLEANED FILE')\n",
    "        pass1_score_cleaned_fully          = evaluate_functional_correctness(\n",
    "            file_name_cleaned_fully,\n",
    "            k=[1],\n",
    "            mode=mode, )\n",
    "        \n",
    "        print('\\nEVALUATING FULLY CLEANED LIGHT FILE')\n",
    "        pass1_score_cleaned_fully_light    = evaluate_functional_correctness(\n",
    "            file_name_cleaned_fully_light,\n",
    "            k=[1],\n",
    "            mode=mode, )       \n",
    "                \n",
    "        # enforce the order of cleaning modes\n",
    "        local_scores = [ pass1_score_raw['pass@1'], pass1_score_cleaned_partially['pass@1'],\n",
    "                         pass1_score_cleaned_fully['pass@1'], pass1_score_cleaned_fully_light['pass@1'], ]        \n",
    "        final_res[model_name].extend( local_scores )\n",
    "        \n",
    "        print('\\nResults for:', file_name)\n",
    "        print('\\nRaw score')\n",
    "        print('Partially cleaned score')\n",
    "        print('Fully cleaned score')\n",
    "        print('Fully light cleaned score\\n')\n",
    "        print(*local_scores, sep='\\n')\n",
    "        print('\\n', '='*75, '\\n', sep='')\n",
    "    print('Interim  results:', *final_res.items(), sep='\\n')\n",
    "    print('\\n', '='*100, '\\n', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12970a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phixtral-2x2</th>\n",
       "      <th>Solar-10.7B</th>\n",
       "      <th>Llama-3.1-8B</th>\n",
       "      <th>codegemma-7b-it</th>\n",
       "      <th>deepseek-coder-6.7b</th>\n",
       "      <th>OpenCodeInterpreter-DS-6.7B</th>\n",
       "      <th>Artigenz-Coder-DS-6.7B</th>\n",
       "      <th>CodeQwen1.5-7B-Chat</th>\n",
       "      <th>Nxcode-CQ-7B-orpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.197531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.209877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.209877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.216049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.191358</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.228395</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.209877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.216049</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.216049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.216049</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.154321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.228395</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.197531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.228395</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.197531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    phixtral-2x2  Solar-10.7B  Llama-3.1-8B  codegemma-7b-it  \\\n",
       "0       0.024691     0.024691      0.000000         0.000000   \n",
       "1       0.129630     0.055556      0.222222         0.117284   \n",
       "2       0.123457     0.092593      0.179012         0.141975   \n",
       "3       0.129630     0.092593      0.222222         0.148148   \n",
       "4       0.012346     0.000000      0.000000         0.000000   \n",
       "5       0.123457     0.049383      0.160494         0.111111   \n",
       "6       0.129630     0.074074      0.191358         0.179012   \n",
       "7       0.135802     0.074074      0.216049         0.179012   \n",
       "8       0.012346     0.000000      0.000000         0.000000   \n",
       "9       0.086420     0.037037      0.203704         0.135802   \n",
       "10      0.117284     0.086420      0.234568         0.166667   \n",
       "11      0.123457     0.086420      0.234568         0.166667   \n",
       "\n",
       "    deepseek-coder-6.7b  OpenCodeInterpreter-DS-6.7B  Artigenz-Coder-DS-6.7B  \\\n",
       "0              0.006173                     0.024691                0.024691   \n",
       "1              0.271605                     0.277778                0.277778   \n",
       "2              0.271605                     0.265432                0.234568   \n",
       "3              0.271605                     0.277778                0.277778   \n",
       "4              0.000000                     0.000000                0.000000   \n",
       "5              0.271605                     0.265432                0.240741   \n",
       "6              0.259259                     0.265432                0.228395   \n",
       "7              0.271605                     0.265432                0.246914   \n",
       "8              0.000000                     0.000000                0.000000   \n",
       "9              0.216049                     0.271605                0.240741   \n",
       "10             0.228395                     0.290123                0.222222   \n",
       "11             0.228395                     0.283951                0.240741   \n",
       "\n",
       "    CodeQwen1.5-7B-Chat  Nxcode-CQ-7B-orpo  \n",
       "0              0.024691           0.006173  \n",
       "1              0.197531           0.197531  \n",
       "2              0.203704           0.209877  \n",
       "3              0.203704           0.209877  \n",
       "4              0.000000           0.012346  \n",
       "5              0.209877           0.216049  \n",
       "6              0.222222           0.209877  \n",
       "7              0.222222           0.216049  \n",
       "8              0.000000           0.018519  \n",
       "9              0.160494           0.154321  \n",
       "10             0.185185           0.197531  \n",
       "11             0.185185           0.197531  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols   = [c for c in model_names if c in final_res]\n",
    "df_res = pd.DataFrame(final_res)\n",
    "df_res = df_res[cols]\n",
    "results_file = 'results/indiv_model_results_lbpp_top-p_087_20250623.csv'\n",
    "df_res.to_csv(results_file, index=False)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e5d530",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unknown_variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43munknown_variable\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unknown_variable' is not defined"
     ]
    }
   ],
   "source": [
    "unknown_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb7709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52e2e703",
   "metadata": {},
   "source": [
    "## 5. Debug errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7601962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load file with results for debugging\n",
    "file_name = 'logs/final-round-one-model/BigCode/Nous-Hermes-2-Solar-10.7B/BigCode_Nous-Hermes-2-Solar-10.7B_complete_code_prompt_basic_temperature1.0_topP1.0_completions_20250402_030815_4464.jsonl'\n",
    "results1 = list(stream_jsonl(file_name))\n",
    "file_name = 'logs/final-round-one-model/BigCode/Nous-Hermes-2-Solar-10.7B/BigCode_Nous-Hermes-2-Solar-10.7B_complete_code_prompt_temperature1.0_topP1.0_completions_20250402_031004_3447.jsonl'\n",
    "results2 = list(stream_jsonl(file_name))\n",
    "len(results1), len(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2a063cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BigCodeBench/1138']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which key is missing\n",
    "keys1 = [i['task_id'] for i in results1]\n",
    "keys2 = [i['task_id'] for i in results2]\n",
    "[key for key in keys2 if key not in keys1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b1861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_res = { 'task_id': 'BigCodeBench/1138', 'completion': 'completion' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acabe3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1.append( one_res )\n",
    "len(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d9cb432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'BigCodeBench/1138', 'completion': 'completion'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1[-1]['task_id'] = 'BigCodeBench/1138'\n",
    "results1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "362778fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'logs/final-round-one-model/BigCode/Nous-Hermes-2-Solar-10.7B/BigCode_Nous-Hermes-2-Solar-10.7B_complete_code_prompt_basic_temperature1.0_topP1.0_completions_20250402_030815_4464.jsonl'\n",
    "write_jsonl(file_name, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dadf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "33718cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n: int):\n",
      "    if n <= 0:\n",
      "        return \"Input should be a positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "\n",
      "# Test cases\n",
      "print(fib(10))  # Expected output: 34\n",
      "print(fib(1))   # Expected output: 0\n",
      "print(fib(8))   # Expected output: 13\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "def fib(n: int):\n",
      "    if n <= 0:\n",
      "        return \"Input should be a positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "\n",
      "# Test cases\n",
      "print(fib(10))  # Expected output: 34\n",
      "print(fib(1))   # Expected output: 0\n",
      "print(fib(8))   # Expected output: 13\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "from typing import *\n",
      "\n",
      "def fib(n: int):\n",
      "    if n <= 0:\n",
      "        return \"Input should be a positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "\n",
      "# Test cases\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "from typing import *\n",
      "\n",
      "def fib(n: int):\n",
      "    if n <= 0:\n",
      "        return \"Input should be a positive integer.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "\n",
      "# Test cases\n",
      "print(fib(10))  # Expected output: 34\n",
      "print(fib(1))   # Expected output: 0\n",
      "print(fib(8))   # Expected output: 13\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# review\n",
    "idx = 55\n",
    "for res in [results, results_cleaned_partially, results_cleaned_fully, results_cleaned_fully_light]:\n",
    "    print(res[idx]['completion'])\n",
    "    print('\\n', '='*75, '\\n', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f78113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
