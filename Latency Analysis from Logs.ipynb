{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775e62ee",
   "metadata": {},
   "source": [
    "# Analyze Latency in Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ee357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "#from human_eval.data import stream_jsonl, write_jsonl\n",
    "#from helpers import get_code_in_fences, clean_code, clean_code_light, read_problems\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c67709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_elapsed_times_from_file( file_to_parse ):\n",
    "    pattern = re.compile(r'Time elapsed(?: including backoff)?: (\\d+\\.\\d+) seconds')\n",
    "    elapsed_times = []\n",
    "    with open(file_to_parse) as f:\n",
    "        for line in f:\n",
    "            match = pattern.search(line)\n",
    "            if match:\n",
    "                seconds = float(match.group(1))\n",
    "                elapsed_times.append(seconds)\n",
    "    return elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6a1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dd66321",
   "metadata": {},
   "source": [
    "## Rank Datasets and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481c1162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    'phixtral-2x2_8',\n",
    "    'Nous-Hermes-2-Solar-10.7B',\n",
    "    'Meta-Llama-3.1-8B-Instruct',\n",
    "    'codegemma-7b-it',\n",
    "    'deepseek-coder-6.7b-instruct',\n",
    "    'OpenCodeInterpreter-DS-6.7B',\n",
    "    'Artigenz-Coder-DS-6.7B',\n",
    "    'CodeQwen1.5-7B-Chat',\n",
    "    'Nxcode-CQ-7B-orpo',\n",
    "    'phixtral-4x2_8',\n",
    "    'mistral_3b',\n",
    "    'mistral_8B',\n",
    "    'nemo',\n",
    "    'codestral_mamba',\n",
    "    'mistral_7b',\n",
    "    ]\n",
    "print(len(models))\n",
    "dataset_names = ['HumanEval', 'MBPP', 'LBPP', 'BigCode']\n",
    "wdir = '/Users/andrew/Documents/01_documents/GWU_DENG/SEAS_8588_Praxis/2_Code/logs_results/final-round-one-model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7692a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanEval\n",
      "15\n",
      "MBPP\n",
      "15\n",
      "LBPP\n",
      "15\n",
      "BigCode\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# group files by dataset, then by model\n",
    "filepaths_per_dataset = dict()\n",
    "for dataset_name in dataset_names:\n",
    "    filepaths_per_model = defaultdict(list)\n",
    "    wdir_current = wdir + dataset_name\n",
    "    for root, dirs, files in os.walk(wdir_current):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.log'):\n",
    "                current_models = [model for model in models if model in filename]\n",
    "                assert len(current_models)==1, f'Found more than 1 model: {current_models}'\n",
    "                current_model = current_models[0]\n",
    "                                \n",
    "                # extract code execution durations\n",
    "                filepath = os.path.join(root, filename)\n",
    "                elapsed_times = extract_elapsed_times_from_file( filepath )\n",
    "                filepaths_per_model[ current_model ].extend( elapsed_times )\n",
    "    filepaths_per_dataset[ dataset_name ] = filepaths_per_model\n",
    "\n",
    "# print number of models for each dataset\n",
    "for dataset_name in filepaths_per_dataset:\n",
    "    print(dataset_name)\n",
    "    print(len(filepaths_per_dataset[dataset_name]))\n",
    "    \n",
    "#filepaths_per_dataset['HumanEval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061d89b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2850.3186, 5.793330487804878)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore structure\n",
    "temp = filepaths_per_dataset['HumanEval']['CodeQwen1.5-7B-Chat']\n",
    "sum(temp), np.mean(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba00784",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for key1, subdict in filepaths_per_dataset.items():\n",
    "    for key2, lst in subdict.items():\n",
    "        total = sum(lst)\n",
    "        mean = total / len(lst) if lst else float('nan')\n",
    "        rows.append({\n",
    "            'dataset': key1,\n",
    "            'model': key2,\n",
    "            'mean': mean,\n",
    "            'sum': total,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93e8c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>codestral_mamba</td>\n",
       "      <td>2.216548</td>\n",
       "      <td>1090.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>phixtral-2x2_8</td>\n",
       "      <td>19.982338</td>\n",
       "      <td>9831.3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>phixtral-4x2_8</td>\n",
       "      <td>24.086714</td>\n",
       "      <td>11850.6634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>Nxcode-CQ-7B-orpo</td>\n",
       "      <td>6.797984</td>\n",
       "      <td>3344.6079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>Artigenz-Coder-DS-6.7B</td>\n",
       "      <td>7.251943</td>\n",
       "      <td>3567.9562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>mistral_8B</td>\n",
       "      <td>2.686335</td>\n",
       "      <td>1321.6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>mistral_3b</td>\n",
       "      <td>2.640248</td>\n",
       "      <td>1299.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>codegemma-7b-it</td>\n",
       "      <td>7.418158</td>\n",
       "      <td>3649.7338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>10.185030</td>\n",
       "      <td>5011.0347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>CodeQwen1.5-7B-Chat</td>\n",
       "      <td>5.793330</td>\n",
       "      <td>2850.3186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>Nous-Hermes-2-Solar-10.7B</td>\n",
       "      <td>11.707980</td>\n",
       "      <td>5760.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>deepseek-coder-6.7b-instruct</td>\n",
       "      <td>5.208777</td>\n",
       "      <td>2562.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>OpenCodeInterpreter-DS-6.7B</td>\n",
       "      <td>6.392088</td>\n",
       "      <td>3144.9075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>nemo</td>\n",
       "      <td>1.397036</td>\n",
       "      <td>687.3419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>mistral_7b</td>\n",
       "      <td>2.369202</td>\n",
       "      <td>1165.6472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>codestral_mamba</td>\n",
       "      <td>2.966989</td>\n",
       "      <td>4450.4840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>phixtral-2x2_8</td>\n",
       "      <td>17.675052</td>\n",
       "      <td>26512.5777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>phixtral-4x2_8</td>\n",
       "      <td>21.528247</td>\n",
       "      <td>32292.3710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>Nxcode-CQ-7B-orpo</td>\n",
       "      <td>5.692040</td>\n",
       "      <td>8538.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>Artigenz-Coder-DS-6.7B</td>\n",
       "      <td>8.858185</td>\n",
       "      <td>13287.2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>mistral_8B</td>\n",
       "      <td>2.118124</td>\n",
       "      <td>3177.1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>mistral_3b</td>\n",
       "      <td>1.824130</td>\n",
       "      <td>2736.1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>codegemma-7b-it</td>\n",
       "      <td>5.098498</td>\n",
       "      <td>7647.7466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>9.309147</td>\n",
       "      <td>13963.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>CodeQwen1.5-7B-Chat</td>\n",
       "      <td>5.070259</td>\n",
       "      <td>7605.3882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset                         model       mean         sum\n",
       "0   HumanEval               codestral_mamba   2.216548   1090.5416\n",
       "1   HumanEval                phixtral-2x2_8  19.982338   9831.3105\n",
       "2   HumanEval                phixtral-4x2_8  24.086714  11850.6634\n",
       "3   HumanEval             Nxcode-CQ-7B-orpo   6.797984   3344.6079\n",
       "4   HumanEval        Artigenz-Coder-DS-6.7B   7.251943   3567.9562\n",
       "5   HumanEval                    mistral_8B   2.686335   1321.6767\n",
       "6   HumanEval                    mistral_3b   2.640248   1299.0020\n",
       "7   HumanEval               codegemma-7b-it   7.418158   3649.7338\n",
       "8   HumanEval    Meta-Llama-3.1-8B-Instruct  10.185030   5011.0347\n",
       "9   HumanEval           CodeQwen1.5-7B-Chat   5.793330   2850.3186\n",
       "10  HumanEval     Nous-Hermes-2-Solar-10.7B  11.707980   5760.3262\n",
       "11  HumanEval  deepseek-coder-6.7b-instruct   5.208777   2562.7184\n",
       "12  HumanEval   OpenCodeInterpreter-DS-6.7B   6.392088   3144.9075\n",
       "13  HumanEval                          nemo   1.397036    687.3419\n",
       "14  HumanEval                    mistral_7b   2.369202   1165.6472\n",
       "15       MBPP               codestral_mamba   2.966989   4450.4840\n",
       "16       MBPP                phixtral-2x2_8  17.675052  26512.5777\n",
       "17       MBPP                phixtral-4x2_8  21.528247  32292.3710\n",
       "18       MBPP             Nxcode-CQ-7B-orpo   5.692040   8538.0597\n",
       "19       MBPP        Artigenz-Coder-DS-6.7B   8.858185  13287.2776\n",
       "20       MBPP                    mistral_8B   2.118124   3177.1867\n",
       "21       MBPP                    mistral_3b   1.824130   2736.1948\n",
       "22       MBPP               codegemma-7b-it   5.098498   7647.7466\n",
       "23       MBPP    Meta-Llama-3.1-8B-Instruct   9.309147  13963.7204\n",
       "24       MBPP           CodeQwen1.5-7B-Chat   5.070259   7605.3882"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "print(df.shape)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1629d113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>Nxcode-CQ-7B-orpo</td>\n",
       "      <td>6.797984</td>\n",
       "      <td>3344.6079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>Nxcode-CQ-7B-orpo</td>\n",
       "      <td>5.692040</td>\n",
       "      <td>8538.0597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LBPP</td>\n",
       "      <td>Nxcode-CQ-7B-orpo</td>\n",
       "      <td>12.517915</td>\n",
       "      <td>6083.7067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BigCode</td>\n",
       "      <td>Nxcode-CQ-7B-orpo</td>\n",
       "      <td>12.070811</td>\n",
       "      <td>18106.2162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset              model       mean         sum\n",
       "3   HumanEval  Nxcode-CQ-7B-orpo   6.797984   3344.6079\n",
       "18       MBPP  Nxcode-CQ-7B-orpo   5.692040   8538.0597\n",
       "33       LBPP  Nxcode-CQ-7B-orpo  12.517915   6083.7067\n",
       "48    BigCode  Nxcode-CQ-7B-orpo  12.070811  18106.2162"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['model']=='Nxcode-CQ-7B-orpo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0bbb051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>average_latency</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBPP</td>\n",
       "      <td>7.587069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval</td>\n",
       "      <td>7.742248</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BigCode</td>\n",
       "      <td>14.475852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LBPP</td>\n",
       "      <td>18.403980</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  average_latency  rank\n",
       "0       MBPP         7.587069     1\n",
       "1  HumanEval         7.742248     2\n",
       "2    BigCode        14.475852     3\n",
       "3       LBPP        18.403980     4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average latency by dataset\n",
    "dset_distrib = []\n",
    "for dataset in dataset_names:\n",
    "    mean = np.mean( df[df['dataset']==dataset]['mean'].values )\n",
    "    dset_distrib.append({\n",
    "                'dataset': dataset,\n",
    "                'average_latency': mean,\n",
    "            })\n",
    "df_dsets = pd.DataFrame( dset_distrib ).sort_values(by='average_latency').reset_index(drop=True)\n",
    "df_dsets['rank'] = df_dsets['average_latency'].rank(method='dense', ascending=True).astype(int)\n",
    "df_dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b55bcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>average_latency</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nemo</td>\n",
       "      <td>2.629084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral_7b</td>\n",
       "      <td>3.231326</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mistral_8B</td>\n",
       "      <td>3.525050</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codestral_mamba</td>\n",
       "      <td>3.829256</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistral_3b</td>\n",
       "      <td>4.322546</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CodeQwen1.5-7B-Chat</td>\n",
       "      <td>8.196508</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek-coder-6.7b-instruct</td>\n",
       "      <td>8.835947</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nxcode-CQ-7B-orpo</td>\n",
       "      <td>9.269687</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>codegemma-7b-it</td>\n",
       "      <td>9.761839</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OpenCodeInterpreter-DS-6.7B</td>\n",
       "      <td>11.123243</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Artigenz-Coder-DS-6.7B</td>\n",
       "      <td>11.603654</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>13.529942</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>phixtral-2x2_8</td>\n",
       "      <td>27.556292</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nous-Hermes-2-Solar-10.7B</td>\n",
       "      <td>29.986195</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>phixtral-4x2_8</td>\n",
       "      <td>33.383734</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  average_latency  rank\n",
       "0                           nemo         2.629084     1\n",
       "1                     mistral_7b         3.231326     2\n",
       "2                     mistral_8B         3.525050     3\n",
       "3                codestral_mamba         3.829256     4\n",
       "4                     mistral_3b         4.322546     5\n",
       "5            CodeQwen1.5-7B-Chat         8.196508     6\n",
       "6   deepseek-coder-6.7b-instruct         8.835947     7\n",
       "7              Nxcode-CQ-7B-orpo         9.269687     8\n",
       "8                codegemma-7b-it         9.761839     9\n",
       "9    OpenCodeInterpreter-DS-6.7B        11.123243    10\n",
       "10        Artigenz-Coder-DS-6.7B        11.603654    11\n",
       "11    Meta-Llama-3.1-8B-Instruct        13.529942    12\n",
       "12                phixtral-2x2_8        27.556292    13\n",
       "13     Nous-Hermes-2-Solar-10.7B        29.986195    14\n",
       "14                phixtral-4x2_8        33.383734    15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average latency by model\n",
    "model_distrib = []\n",
    "for model in models:\n",
    "    mean = np.mean( df[df['model']==model]['mean'].values )\n",
    "    model_distrib.append({\n",
    "                'model': model,\n",
    "                'average_latency': mean,\n",
    "            })\n",
    "df_models = pd.DataFrame( model_distrib ).sort_values(by='average_latency').reset_index(drop=True)\n",
    "df_models['rank'] = df_models['average_latency'].rank(method='dense', ascending=True).astype(int)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3cf38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e5939fa",
   "metadata": {},
   "source": [
    "## Rank Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4c4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'complete_code_prompt_basic',\n",
    "    'complete_code_prompt_full',\n",
    "    'complete_code_prompt',\n",
    "    'complete_task_prompt_basic',\n",
    "    'complete_task_prompt_full',\n",
    "    'complete_task_prompt',    \n",
    "]\n",
    "wdir = '/Users/andrew/Documents/01_documents/GWU_DENG/SEAS_8588_Praxis/2_Code/logs_results/final-round-one-model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a956446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete_code_prompt_full\n",
      "9960\n",
      "complete_code_prompt\n",
      "9960\n",
      "complete_code_prompt_basic\n",
      "9463\n",
      "complete_task_prompt_full\n",
      "9930\n",
      "complete_task_prompt\n",
      "9930\n",
      "complete_task_prompt_basic\n",
      "9930\n"
     ]
    }
   ],
   "source": [
    "# group files by prompt\n",
    "filepaths_per_prompt = defaultdict(list)\n",
    "for dataset_name in dataset_names:\n",
    "    wdir_current = wdir + dataset_name\n",
    "    for root, dirs, files in os.walk(wdir_current):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.log'):\n",
    "                for prompt in prompts:\n",
    "                    if prompt in filename:\n",
    "                        current_prompt = prompt\n",
    "                        break\n",
    "                                \n",
    "                # extract code execution durations\n",
    "                filepath = os.path.join(root, filename)\n",
    "                elapsed_times = extract_elapsed_times_from_file( filepath )\n",
    "                filepaths_per_prompt[ current_prompt ].extend( elapsed_times )\n",
    "\n",
    "# print number of models for each dataset\n",
    "for prompt in filepaths_per_prompt:\n",
    "    print(prompt)\n",
    "    print(len(filepaths_per_prompt[prompt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "243dce65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>average_latency</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complete_task_prompt_full</td>\n",
       "      <td>6.787204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complete_code_prompt_full</td>\n",
       "      <td>10.644450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complete_task_prompt</td>\n",
       "      <td>10.763853</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complete_task_prompt_basic</td>\n",
       "      <td>13.151265</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complete_code_prompt_basic</td>\n",
       "      <td>13.410396</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>complete_code_prompt</td>\n",
       "      <td>13.792369</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prompt  average_latency  rank\n",
       "0   complete_task_prompt_full         6.787204     1\n",
       "1   complete_code_prompt_full        10.644450     2\n",
       "2        complete_task_prompt        10.763853     3\n",
       "3  complete_task_prompt_basic        13.151265     4\n",
       "4  complete_code_prompt_basic        13.410396     5\n",
       "5        complete_code_prompt        13.792369     6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average latency by prompt\n",
    "prompt_distrib = []\n",
    "for prompt in filepaths_per_prompt:\n",
    "    mean = np.mean( filepaths_per_prompt[prompt] )\n",
    "    prompt_distrib.append({\n",
    "                'prompt': prompt,\n",
    "                'average_latency': mean,\n",
    "            })\n",
    "df_pprompts = pd.DataFrame( prompt_distrib ).sort_values(by='average_latency').reset_index(drop=True)\n",
    "df_pprompts['rank'] = df_pprompts['average_latency'].rank(method='dense', ascending=True).astype(int)\n",
    "df_pprompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace14f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
